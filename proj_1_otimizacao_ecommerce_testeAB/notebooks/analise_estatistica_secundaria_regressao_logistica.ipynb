{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ebabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as Bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f523fb7",
   "metadata": {},
   "source": [
    "# Carregamento e Pré-Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5ce809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('C:/Users/natal/nataliaguarnieri/proj_1_otimizacao_ecommerce_testeAB/data/ecommerce_events_data.csv')\n",
    "    print('Dados carregados com sucesso!')\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Certifique-se de que o arquivo 'ecommerce_events_data.csv' está dentro da pasta 'data'.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d68b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Identificar usuários únicos e seus atributos\n",
    "\n",
    "# Vamos usar o último evento de cada usuário para capturar seus atributos\n",
    "user_attributes = df.sort_values('timestamp').drop_duplicates(subset='user_id', keep='last')\n",
    "user_attributes = user_attributes[['user_id', 'group', 'device_type', 'traffic_source', 'location']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080a0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2: Criar a variável binária de Sucesso (Comprou = 1, Não Comprou = 0)\n",
    "users_who_purchased = df[df['event_type'] == 'purchase']['user_id'].unique()\n",
    "\n",
    "user_attributes['converted'] = np.where(\n",
    "    user_attributes['user_id'].isin(users_who_purchased),\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed2c76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pré-processamento concluído.\n",
      "DataFrame pronto para modelagem (apenas usuários únicos, com variável 'converted' e dummies).\n",
      "Número total de usuários: 100000\n"
     ]
    }
   ],
   "source": [
    "# Passo 3: Criar variáveis Dummy para o Modelo\n",
    "\n",
    "# Renomeia o grupo 'test' para 1 e o 'control' para 0\n",
    "user_attributes['is_test_group'] = np.where(user_attributes['group'] == 'test', 1, 0)\n",
    "\n",
    "# Criar os dummies para os outros segmentos, removendo a primeira categoria para evitar multicolinearidade\n",
    "df_model = pd.get_dummies(\n",
    "    user_attributes,\n",
    "    columns=['device_type', 'traffic_source', 'location'],\n",
    "    drop_first=True,\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Adicionar a constante (Intercept) necessária para o modelo statsmodels\n",
    "df_model = sm.add_constant(df_model, prepend=False)\n",
    "\n",
    "print(\"\\nPré-processamento concluído.\")\n",
    "print(\"DataFrame pronto para modelagem (apenas usuários únicos, com variável 'converted' e dummies).\")\n",
    "print(f\"Número total de usuários: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7ea2",
   "metadata": {},
   "source": [
    "# Criação do Modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811270ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável Dependente (Y): O que queremos prever (conversão)\n",
    "Y = df_model['converted']\n",
    "\n",
    "# Variável Independente (X): O que vai prever a conversão\n",
    "# Incluímos o grupo de teste e todas as variáveis de segmento (dummies)\n",
    "# Removemos colunas que não são preditoras (user_id, group, etc.)\n",
    "exclude_cols = ['user_id', 'group', 'converted', 'device_type', 'traffic_source', 'location']\n",
    "X = df_model.drop(columns=exclude_cols, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5716119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Criação do Modelo\n",
    "\n",
    "logit_model = sm.Logit(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf1b7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.147923\n",
      "         Iterations 8\n",
      "\n",
      "======================================================================\n",
      "RESUMO COMPLETO DA REGRESSÃO LOGÍSTICA (STATSMODELS)\n",
      "======================================================================\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              converted   No. Observations:               100000\n",
      "Model:                          Logit   Df Residuals:                    99988\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Thu, 25 Sep 2025   Pseudo R-squ.:                0.006903\n",
      "Time:                        11:15:24   Log-Likelihood:                -14792.\n",
      "converged:                       True   LL-Null:                       -14895.\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.991e-38\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "is_test_group               0.5017      0.036     14.001      0.000       0.431       0.572\n",
      "device_type_Mobile          0.0212      0.041      0.523      0.601      -0.058       0.101\n",
      "device_type_Tablet          0.0901      0.078      1.157      0.247      -0.063       0.243\n",
      "traffic_source_Organic      0.0557      0.054      1.039      0.299      -0.049       0.161\n",
      "traffic_source_Paid         0.0541      0.056      0.968      0.333      -0.055       0.164\n",
      "traffic_source_Social       0.0673      0.064      1.050      0.294      -0.058       0.193\n",
      "location_Curitiba           0.0279      0.060      0.463      0.643      -0.090       0.146\n",
      "location_Porto Alegre      -0.0129      0.061     -0.212      0.832      -0.132       0.106\n",
      "location_Rio de Janeiro    -0.0031      0.060     -0.051      0.960      -0.121       0.115\n",
      "location_Salvador           0.0040      0.060      0.066      0.948      -0.114       0.122\n",
      "location_São Paulo          0.0421      0.060      0.703      0.482      -0.075       0.160\n",
      "const                      -3.6908      0.065    -56.614      0.000      -3.819      -3.563\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Passo 2: Treinamento/Ajuste do Modelo\n",
    "\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMO COMPLETO DA REGRESSÃO LOGÍSTICA (STATSMODELS)\")\n",
    "print(\"=\"*70)\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7b840",
   "metadata": {},
   "source": [
    "# Interpretação com ODDS Ratios (Razão de Chances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad70db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ODDS RATIOS (RAZÃO DE CHANCES) E VALORES-P\n",
      "======================================================================\n",
      "Variáveis que impactam significativamente a conversão (P-value < 0.05):\n",
      "|               |   Odds Ratio (OR) |   P-value |\n",
      "|:--------------|------------------:|----------:|\n",
      "| is_test_group |            1.6515 |    0.0000 |\n",
      "| const         |            0.0250 |    0.0000 |\n"
     ]
    }
   ],
   "source": [
    "# Odds Ratios são mais fáceis de interpretar:\n",
    "# - OR > 1.0: Aumenta a chance de conversão.\n",
    "# - OR < 1.0: Diminui a chance de conversão.\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ODDS RATIOS (RAZÃO DE CHANCES) E VALORES-P\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Cria um DataFrame com os resultados\n",
    "\n",
    "odds_ratios = pd.DataFrame({\n",
    "    'Odds Ratio (OR)': np.exp(result.params),\n",
    "    'P-value': result.pvalues\n",
    "})\n",
    "\n",
    "# Formatação e Ordenação\n",
    "\n",
    "odds_ratios = odds_ratios.sort_values(by='Odds Ratio (OR)', ascending=False)\n",
    "odds_ratios = odds_ratios[odds_ratios['P-value'] < 0.05] # Filtra apenas o que é estatisticamente significativo\n",
    "\n",
    "print(\"Variáveis que impactam significativamente a conversão (P-value < 0.05):\")\n",
    "print(odds_ratios.to_markdown(floatfmt=\".4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
